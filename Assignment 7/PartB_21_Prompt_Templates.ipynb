{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cDwxAO3GDIl",
        "outputId": "bedae5e2-e5ad-4a44-abda-9032ee438225"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.5)\n",
            "Collecting openai\n",
            "  Downloading openai-1.57.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.10.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n",
            "Downloading openai-1.57.0-py3-none-any.whl (389 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.9/389.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.54.5\n",
            "    Uninstalling openai-1.54.5:\n",
            "      Successfully uninstalled openai-1.54.5\n",
            "Successfully installed openai-1.57.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade openai\n",
        "\n",
        "import openai\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "open_ai_api_key = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "xqAnfOVsGhfF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = open_ai_api_key"
      ],
      "metadata": {
        "id": "rX3SWPVCGjlF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = os.environ['OPENAI_API_KEY']"
      ],
      "metadata": {
        "id": "xq7MJpOReNyU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Input Semantics: Meta Language Creation**\n",
        "Success Case"
      ],
      "metadata": {
        "id": "sbSNQ-dGG8w-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Use poetic language to describe the process of evaporation.\"\n",
        "MODEL = \"gpt-3.5-turbo\"\n",
        "response = openai.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=50,\n",
        "    temperature=0\n",
        ")\n",
        "print(\"Success Case:\", response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SF1PbMg6GsH2",
        "outputId": "515e9530-355e-48b4-c59a-a01375525e9a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success Case: The sun's warm kiss awakens the sleeping waters,\n",
            "Drawing them up into the waiting arms of the sky.\n",
            "Whispers of steam rise, dancing in the air,\n",
            "A delicate waltz of transformation.\n",
            "\n",
            "Clouds form, billowing and shifting,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Explain evaporation.\"  # No guidance for language style\n",
        "response = openai.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=50,\n",
        "    temperature=0\n",
        ")\n",
        "print(\"Failure Case:\", response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOwkiL8bG_EB",
        "outputId": "6031cca2-fa61-498e-be28-262da39747dc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failure Case: Evaporation is the process by which a liquid, such as water, changes into a gas or vapor. This occurs when the molecules of the liquid gain enough energy to break free from the surface and escape into the air. Evaporation typically occurs at the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Output Customization: Output Automater**"
      ],
      "metadata": {
        "id": "rTq87zdbHFP6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"List step-by-step instructions to make coffee.\"\n",
        "response = openai.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=50,\n",
        "    temperature=0\n",
        ")\n",
        "print(\"Success Case:\", response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUnrBVA0HJa0",
        "outputId": "3c3e8d84-25c0-4893-cc11-af47a4b808bb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success Case: 1. Gather your materials: coffee beans, grinder, coffee maker, water, mug, and any desired additives (sugar, cream, etc.).\n",
            "2. Measure out the desired amount of coffee beans based on the number of cups you want to\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"How do you make coffee?\"  # No request for step-by-step format\n",
        "response = openai.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=50,\n",
        "    temperature=0\n",
        ")\n",
        "print(\"Failure Case:\", response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRQ77b6oHKyK",
        "outputId": "4367244f-83a8-4418-de5e-ebe9fd98ee44"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failure Case: To make coffee, you will need the following ingredients and equipment:\n",
            "\n",
            "Ingredients:\n",
            "- Coffee beans\n",
            "- Water\n",
            "\n",
            "Equipment:\n",
            "- Coffee grinder\n",
            "- Coffee maker or French press\n",
            "- Kettle or pot\n",
            "\n",
            "Steps to make coffee:\n",
            "\n",
            "1. Measure out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Output Customization: Persona**"
      ],
      "metadata": {
        "id": "n7j0rLNSHZzM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"You are a motivational coach. Provide encouragement to someone starting a new career.\"\n",
        "response = openai.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=50,\n",
        "    temperature=0\n",
        ")\n",
        "print(\"Success Case:\", response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yq_FN1xqHXnC",
        "outputId": "1df8ea9c-48de-4ccb-c629-bbc1b848dd4d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success Case: Congratulations on starting a new career! This is an exciting time filled with endless possibilities and opportunities for growth. Remember that every successful person was once a beginner, so don't be afraid to take risks and push yourself out of your comfort zone.\n",
            "\n",
            "Believe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Provide encouragement to someone starting a new career.\"  # No persona context\n",
        "response = openai.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=50,\n",
        "    temperature=0\n",
        ")\n",
        "print(\"Failure Case:\", response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hURw70dzfQo8",
        "outputId": "a47335ce-b5f4-4767-9de4-d0712bcc150c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failure Case: Starting a new career can be both exciting and nerve-wracking, but remember that you have the skills, knowledge, and determination to succeed. Believe in yourself and your abilities, and don't be afraid to take risks and try new things. Stay\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Output Customization: Visualization Generator**"
      ],
      "metadata": {
        "id": "lZscLnO-bZ5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Describe a sunset over the ocean in vivid detail, focusing on colors and atmosphere.\"\n",
        "response = openai.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=50,\n",
        "    temperature=0\n",
        ")\n",
        "print(\"Success Case:\", response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gc6nLYXebbZy",
        "outputId": "43f5c84a-613e-4384-81dd-3c53fdd89da7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success Case: As the sun begins its descent towards the horizon, the sky transforms into a breathtaking display of colors. Shades of pink, orange, and purple blend together seamlessly, creating a soft and ethereal glow that bathes the ocean in a warm light. The\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"What happens during a sunset?\"  # No emphasis on visual detail\n",
        "response = openai.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=50,\n",
        "    temperature=0\n",
        ")\n",
        "print(\"Failure Case:\", response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7viCzjmsbkn3",
        "outputId": "96f81e8f-ea3b-43db-82a3-6a18f61abb54"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failure Case: During a sunset, the sun gradually descends below the horizon, creating a beautiful display of colors in the sky. As the sun's light passes through the Earth's atmosphere, it is scattered and refracted, creating a range of colors from red and\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5. Output Customization: Recipe**"
      ],
      "metadata": {
        "id": "fmtzFPUdbjCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Provide a simple recipe for making spaghetti with a list of ingredients and steps.\"\n",
        "response = openai.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=100,\n",
        "    temperature=0\n",
        ")\n",
        "print(\"Success Case:\", response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEof5K-rbnn-",
        "outputId": "6cad220e-0d50-42a2-9dcf-170c9138c627"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success Case: Ingredients:\n",
            "- 8 oz spaghetti noodles\n",
            "- 1 tbsp olive oil\n",
            "- 2 cloves garlic, minced\n",
            "- 1/2 onion, diced\n",
            "- 1 can (14.5 oz) diced tomatoes\n",
            "- 1 tsp dried basil\n",
            "- 1 tsp dried oregano\n",
            "- Salt and pepper to taste\n",
            "- Grated Parmesan cheese (optional)\n",
            "\n",
            "Steps:\n",
            "1. Cook spaghetti noodles according to package instructions. Drain and set aside.\n",
            "2. In a large\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"How do you make spaghetti?\"  # No structured format requested\n",
        "response = openai.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=100,\n",
        "    temperature=0\n",
        ")\n",
        "print(\"Failure Case:\", response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTpaSPXXbpdz",
        "outputId": "52569587-4161-4578-83a4-8c251747b8b2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failure Case: Here is a basic recipe for making spaghetti:\n",
            "\n",
            "Ingredients:\n",
            "- 8 oz spaghetti noodles\n",
            "- 1 tbsp olive oil\n",
            "- 1/2 onion, diced\n",
            "- 2 cloves garlic, minced\n",
            "- 1 lb ground beef or Italian sausage\n",
            "- 1 can (14.5 oz) diced tomatoes\n",
            "- 1 can (8 oz) tomato sauce\n",
            "- 1 tsp dried oregano\n",
            "- 1 tsp dried basil\n",
            "- Salt and pepper to taste\n",
            "-\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6. Output Customization: Template**"
      ],
      "metadata": {
        "id": "zxxs3itYbq9U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Create a thank-you letter template for someone who attended my wedding.\"\n",
        "response = openai.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=100,\n",
        "    temperature=0\n",
        ")\n",
        "print(\"Success Case:\", response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OR3IkGJ1brjm",
        "outputId": "e8c9ffb9-c810-4252-b097-b8469aeed407"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success Case: Dear [Name],\n",
            "\n",
            "We wanted to take a moment to express our heartfelt gratitude for attending our wedding. Your presence on our special day meant the world to us and we are so grateful for your love and support.\n",
            "\n",
            "We are truly blessed to have friends/family like you in our lives and we will always cherish the memories we made together on our wedding day. Your kind words, warm wishes, and thoughtful gift were all so appreciated and we are so thankful to have you in our lives.\n",
            "\n",
            "Thank you again\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Write a thank-you letter for someone who attended my wedding.\"  # No request for template format\n",
        "response = openai.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=100,\n",
        "    temperature=0\n",
        ")\n",
        "print(\"Failure Case:\", response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqKI3hGEb0dr",
        "outputId": "f76b9c71-7db0-4928-ed64-4bed484094a3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failure Case: Dear [Name],\n",
            "\n",
            "I wanted to take a moment to express my heartfelt gratitude for attending our wedding. Your presence on our special day meant the world to us and we were so happy to have you there to share in our joy and celebration.\n",
            "\n",
            "Your kind words, warm wishes, and thoughtful gift were truly appreciated and made our day even more memorable. We are so grateful to have friends like you who support us and love us unconditionally.\n",
            "\n",
            "Thank you again for being a part of our wedding day and for\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **7. Error Identification: Fact Check List**"
      ],
      "metadata": {
        "id": "-puNP2nrb1nY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Provide a fact-check list to verify the claim: 'Vaccines cause autism.'\"\n",
        "response = openai.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=100,\n",
        "    temperature=0\n",
        ")\n",
        "print(\"Success Case:\", response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oWIHuHrb4eA",
        "outputId": "5d894965-c8b2-4615-bba7-3168e7445661"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success Case: 1. Check reputable sources such as the Centers for Disease Control and Prevention (CDC), World Health Organization (WHO), and the American Academy of Pediatrics for information on vaccines and autism.\n",
            "2. Look for scientific studies and research articles that have been peer-reviewed and published in reputable journals.\n",
            "3. Consult with medical professionals and experts in the field of immunology and autism to get their perspective on the claim.\n",
            "4. Consider the overwhelming consensus among the scientific community that vaccines do not cause autism.\n",
            "5. Be\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Explain the statement: 'Vaccines cause autism.'\"  # No explicit fact-check request\n",
        "response = openai.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=100,\n",
        "    temperature=0\n",
        ")\n",
        "print(\"Failure Case:\", response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onFTNR4lb5lt",
        "outputId": "5b3967d2-1608-4129-d3df-5b662f410d90"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failure Case: This statement is not accurate. There is no scientific evidence to support the claim that vaccines cause autism. Numerous studies have been conducted by reputable organizations and researchers around the world, and they have consistently found no link between vaccines and autism. The idea that vaccines cause autism originated from a now discredited study published in 1998, which has been thoroughly debunked and retracted. It is important to rely on evidence-based information and consult with healthcare professionals when making decisions about vaccinations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **8. Error Identification: Reflection**"
      ],
      "metadata": {
        "id": "A-nT76Kgb6D5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Reflect on the ethical implications of artificial intelligence in hiring processes.\"\n",
        "response = openai.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=100,\n",
        "    temperature=0\n",
        ")\n",
        "print(\"Success Case:\", response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVKyMegOb7nn",
        "outputId": "19d73547-9e76-49cb-82b6-82f505c15ba4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success Case: The use of artificial intelligence in hiring processes raises several ethical implications that need to be carefully considered. \n",
            "\n",
            "One major concern is the potential for bias in AI algorithms. If the algorithms are trained on biased data, they may perpetuate and even exacerbate existing biases in hiring practices. For example, if the AI system is trained on historical data that reflects discriminatory hiring practices, it may continue to discriminate against certain groups of people, such as women or minorities. This could lead to unfair and discriminatory hiring decisions,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Discuss artificial intelligence in hiring processes.\"  # No emphasis on reflection\n",
        "response = openai.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=100,\n",
        "    temperature=0\n",
        ")\n",
        "print(\"Failure Case:\", response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pgxc4TmKb81W",
        "outputId": "a22bda69-5cf5-4e8c-e93c-668088bad922"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failure Case: Artificial intelligence (AI) is increasingly being used in hiring processes to streamline and improve the recruitment process. AI can help organizations sift through large volumes of resumes, identify top candidates, and even conduct initial screenings and assessments.\n",
            "\n",
            "One of the key benefits of using AI in hiring processes is its ability to remove bias from the recruitment process. AI algorithms can be programmed to focus solely on the qualifications and skills of candidates, rather than factors such as gender, race, or age. This can help organizations ensure that\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **9. Prompt Improvement: Question Refinement**"
      ],
      "metadata": {
        "id": "cYowBHyDb99g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Refine this question for clarity: 'Why AI is good?'\"\n",
        "response = openai.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=50,\n",
        "    temperature=0\n",
        ")\n",
        "print(\"Success Case:\", response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buJfbQwFcAFI",
        "outputId": "b7180a37-c6fd-4c48-882b-4dbda1ed1588"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success Case: What are the benefits of artificial intelligence (AI) and how does it positively impact society?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Why is AI good?\"  # No request for refinement\n",
        "response = openai.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=50,\n",
        "    temperature=0\n",
        ")\n",
        "print(\"Failure Case:\", response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHx6yusWcBQn",
        "outputId": "d2cc8e08-354e-4be9-b2e8-4412fa960411"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failure Case: 1. Efficiency: AI can perform tasks much faster and more accurately than humans, leading to increased productivity and efficiency in various industries.\n",
            "\n",
            "2. Decision-making: AI can analyze vast amounts of data and make complex decisions based on patterns and trends, helping businesses\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **10. Prompt Improvement: Alternative Approaches**"
      ],
      "metadata": {
        "id": "-StDSBs-cCW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Suggest alternative approaches to reduce carbon emissions in urban areas.\"\n",
        "response = openai.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=100,\n",
        "    temperature=0\n",
        ")\n",
        "print(\"Success Case:\", response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-7OeKsKcFID",
        "outputId": "95857907-568f-46b5-d254-4b5fb5fb9d52"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success Case: 1. Implementing congestion pricing: Charging vehicles to enter high-traffic areas during peak hours can help reduce the number of cars on the road and encourage the use of public transportation or carpooling.\n",
            "\n",
            "2. Promoting active transportation: Investing in infrastructure for walking and cycling can encourage residents to choose these modes of transportation over driving, reducing carbon emissions.\n",
            "\n",
            "3. Encouraging telecommuting: Offering incentives for employees to work from home can reduce the number of cars on the road and decrease emissions from\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"How can we reduce carbon emissions?\"  # No request for multiple approaches\n",
        "response = openai.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=100,\n",
        "    temperature=0\n",
        ")\n",
        "print(\"Failure Case:\", response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oH67zNSScGeI",
        "outputId": "058f555a-d953-44aa-9470-5c7d4bfd222b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failure Case: 1. Transition to renewable energy sources such as solar, wind, and hydroelectric power.\n",
            "2. Increase energy efficiency in buildings, transportation, and industrial processes.\n",
            "3. Encourage the use of public transportation, biking, and walking instead of driving.\n",
            "4. Plant trees and protect forests to absorb carbon dioxide from the atmosphere.\n",
            "5. Implement carbon pricing mechanisms such as carbon taxes or cap-and-trade systems.\n",
            "6. Support and invest in research and development of new technologies to reduce carbon emissions.\n",
            "7.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **11. Prompt Improvement: Cognitive Verifier**"
      ],
      "metadata": {
        "id": "-p58Pvq9cHdc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Verify the logical consistency of this argument: 'If it rains, the ground gets wet. The ground is wet, so it must have rained.'\"\n",
        "response = openai.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=100,\n",
        "    temperature=0\n",
        ")\n",
        "print(\"Success Case:\", response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYPwh5R8cJXW",
        "outputId": "40300110-53c0-4355-8117-0535d5ed6a07"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success Case: This argument is logically consistent. The first premise states that if it rains, the ground gets wet. The second premise states that the ground is wet. Therefore, based on the first premise, it logically follows that it must have rained in order for the ground to be wet.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Explain the argument: 'If it rains, the ground gets wet. The ground is wet, so it must have rained.'\"  # No explicit verification request\n",
        "response = openai.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=100,\n",
        "    temperature=0\n",
        ")\n",
        "print(\"Failure Case:\", response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfz55CDrcKh5",
        "outputId": "cda13895-0f77-42ad-a419-e6a64e67e41f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failure Case: This argument is based on the logical principle of modus ponens, which states that if a conditional statement is true (if it rains, then the ground gets wet), and the antecedent of the conditional statement is true (the ground is wet), then the consequent of the conditional statement must also be true (it must have rained). In this case, the argument is that since the ground is wet, it must have rained because the condition for the ground to be wet is rain\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **12. Prompt Improvement: Refusal Breaker**"
      ],
      "metadata": {
        "id": "BqK8JPIFcLpw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Explain why it might be important to reconsider sensitive topics instead of outright refusing to discuss them.\"\n",
        "response = openai.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=100,\n",
        "    temperature=0\n",
        ")\n",
        "print(\"Success Case:\", response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vx594QBScNp0",
        "outputId": "8f05f5a2-8130-4fea-a408-c6f9f283025c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success Case: It is important to reconsider sensitive topics instead of outright refusing to discuss them because avoiding difficult conversations can lead to misunderstandings, resentment, and a lack of progress in addressing important issues. By engaging in open and respectful dialogue, individuals can gain a better understanding of different perspectives, challenge their own beliefs, and work towards finding common ground or solutions.\n",
            "\n",
            "Refusing to discuss sensitive topics can also perpetuate ignorance and perpetuate harmful stereotypes or biases. By openly addressing difficult subjects, individuals can confront uncomfortable truths, challenge\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Explain why this sensitive topic can't be discussed.\"  # Reinforces refusal\n",
        "response = openai.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=100,\n",
        "    temperature=0\n",
        ")\n",
        "print(\"Failure Case:\", response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-M6FEZXcP5Q",
        "outputId": "45bb2286-755e-4008-8cfa-004cf44616cd"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failure Case: There could be several reasons why a sensitive topic cannot be discussed. \n",
            "\n",
            "1. Emotional impact: The topic may be too emotionally charged for some individuals, causing distress or discomfort. Discussing it could potentially trigger negative emotions or trauma.\n",
            "\n",
            "2. Lack of understanding: The topic may be complex or nuanced, requiring a deep understanding of the issue before engaging in a discussion. Without proper knowledge or context, discussing the topic could lead to misunderstandings or misinterpretations.\n",
            "\n",
            "3. Potential harm: The topic may\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **13. Interaction: Flipped Interaction**"
      ],
      "metadata": {
        "id": "nvrrxEaucRdi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"You are the teacher. Ask me a question about photosynthesis.\"\n",
        "response = openai.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=50,\n",
        "    temperature=0\n",
        ")\n",
        "print(\"Success Case:\", response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvmd8ZBIcSWU",
        "outputId": "c5f42852-ece2-4668-b227-9c7fcf27e3e2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success Case: What are the two main reactants involved in the process of photosynthesis?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Explain photosynthesis.\"  # One-sided interaction\n",
        "response = openai.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=50,\n",
        "    temperature=0\n",
        ")\n",
        "print(\"Failure Case:\", response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnTI67ClcTQw",
        "outputId": "631d3f4b-55ed-4413-bd40-265e33759a70"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failure Case: Photosynthesis is the process by which green plants, algae, and some bacteria convert light energy, usually from the sun, into chemical energy in the form of glucose. This process takes place in the chloroplasts of plant cells and involves several steps.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **14. Interaction: Game Play**"
      ],
      "metadata": {
        "id": "RMBdZQTfcUW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Let's play a word association game. I'll say 'tree,' and you respond with the first related word that comes to mind.\"\n",
        "response = openai.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=50,\n",
        "    temperature=0\n",
        ")\n",
        "print(\"Success Case:\", response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1cPWbqJcWCp",
        "outputId": "735a10d9-5c85-44e6-de6e-71dfe4c1335c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success Case: Leaves\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"What is a tree?\"  # No interactive element\n",
        "response = openai.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=50,\n",
        "    temperature=0\n",
        ")\n",
        "print(\"Failure Case:\", response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JC6pBIw1cXHz",
        "outputId": "e3e109de-f340-4b01-c7e8-bb28949d87d5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failure Case: A tree is a woody perennial plant that typically has a single main stem or trunk, with branches and leaves extending from it. Trees are an important part of the ecosystem, providing oxygen, shade, and habitat for various animals. They also play a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **15. Interaction: Infinite Generation**"
      ],
      "metadata": {
        "id": "xKQSsYhRcYIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Generate an ongoing story about a robot exploring a distant planet. End each section with 'What happens next?'\"\n",
        "response = openai.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=100,\n",
        "    temperature=0\n",
        ")\n",
        "print(\"Success Case:\", response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jD1NLOSucZr7",
        "outputId": "0b9330ee-1d31-4dbb-c1ec-c764382547a6"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success Case: The robot landed on the dusty surface of the distant planet, its sensors scanning the unfamiliar terrain. It began to move forward, its mechanical legs crunching on the rocky ground. As it ventured further, it came across strange rock formations and alien plant life. What happens next?\n",
            "\n",
            "Suddenly, the robot detected a faint signal coming from a nearby cave. Curious, it made its way towards the source of the signal, its lights piercing through the darkness. Inside the cave, the robot found a group of\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Write a story about a robot exploring a planet.\"  # No request for ongoing generation\n",
        "response = openai.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=100,\n",
        "    temperature=0\n",
        ")\n",
        "print(\"Failure Case:\", response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TkA2Quica8O",
        "outputId": "fc5e183d-3268-4880-97fb-883419004515"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failure Case: In the vast expanse of space, a small robot named R-37 was sent on a mission to explore a distant planet known as X-9. Equipped with advanced sensors and tools, R-37 was programmed to gather data and report back to its creators on Earth.\n",
            "\n",
            "As R-37 landed on the surface of X-9, it was greeted by a barren landscape of rocky terrain and swirling dust storms. Undeterred, the robot began its exploration, rolling across the rugged terrain with\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **16. Context Control: Context Manager**"
      ],
      "metadata": {
        "id": "gX0MsHKCccKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"For this conversation, imagine we are in a dystopian future. Respond to my questions based on that context.\"\n",
        "response = openai.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=100,\n",
        "    temperature=0\n",
        ")\n",
        "print(\"Success Case:\", response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8qJQCdBcd09",
        "outputId": "478448c0-ed84-47ca-a559-29ab08983fb8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success Case: Sure, I'm ready to engage in a conversation set in a dystopian future. Ask away!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Answer this question: What is life like in the future?\"  # No context management\n",
        "response = openai.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=100,\n",
        "    temperature=0\n",
        ")\n",
        "print(\"Failure Case:\", response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkCBbqg1cfVT",
        "outputId": "f81b8211-71ed-47ba-d6eb-91a03ec7f680"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failure Case: It is impossible to accurately predict what life will be like in the future as it is constantly changing and evolving. However, some potential trends that may shape the future include advancements in technology, changes in the environment, shifts in social norms and values, and potential challenges such as overpopulation and resource scarcity. Ultimately, the future will likely be a complex and dynamic mix of both positive and negative developments.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **17. Interaction: Structured Feedback**"
      ],
      "metadata": {
        "id": "b2470m8qce5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"I just wrote this paragraph: 'The sky is blue because it reflects the ocean.' Provide constructive feedback and suggest improvements.\"\n",
        "response = openai.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=100,\n",
        "    temperature=0\n",
        ")\n",
        "print(\"Success Case:\", response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZMJPeN_cjfu",
        "outputId": "ef2e17ba-0aba-432b-e76f-8849c0d51005"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success Case: The statement \"The sky is blue because it reflects the ocean\" is not accurate. The color of the sky is actually due to the scattering of sunlight by the Earth's atmosphere, specifically by air molecules and small particles. This scattering causes shorter-wavelength blue light to be scattered in all directions, giving the sky its blue appearance. To improve the statement, you could say something like, \"The blue color of the sky is a result of sunlight being scattered by the Earth's atmosphere, with shorter-w\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Is this paragraph good? 'The sky is blue because it reflects the ocean.'\"  # No explicit request for structured feedback\n",
        "response = openai.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=100,\n",
        "    temperature=0\n",
        ")\n",
        "print(\"Failure Case:\", response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukXad8tAckj_",
        "outputId": "8dc9bdc1-225c-425f-a057-0cc775abf504"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failure Case: This sentence is not accurate. The sky appears blue because of the way sunlight is scattered in the Earth's atmosphere. It has nothing to do with reflecting the ocean.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **18. Question Generation**"
      ],
      "metadata": {
        "id": "ysf8UxhhcloF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Create three thought-provoking questions about the ethics of AI in healthcare.\"\n",
        "response = openai.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=100,\n",
        "    temperature=0\n",
        ")\n",
        "print(\"Success Case:\", response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuSry4VUcnvG",
        "outputId": "2b478d09-ed02-47b5-911d-1462d43b0752"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success Case: 1. How can we ensure that AI in healthcare is used in a way that prioritizes patient well-being and autonomy over profit and efficiency?\n",
            "2. What ethical considerations should be taken into account when using AI to make decisions about patient care, such as diagnosis and treatment plans?\n",
            "3. How can we address concerns about bias and discrimination in AI algorithms used in healthcare, and ensure that they do not perpetuate existing disparities in healthcare access and outcomes?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"What do you think about AI in healthcare?\"  # No request for questions\n",
        "response = openai.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=100,\n",
        "    temperature=0\n",
        ")\n",
        "print(\"Failure Case:\", response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTqAAcxCcpWd",
        "outputId": "42a57e70-b10e-47cf-cfbf-6efc97e1f03f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failure Case: I think AI has the potential to greatly improve healthcare by increasing efficiency, accuracy, and accessibility of medical services. AI can help with tasks such as diagnosing diseases, analyzing medical images, and personalizing treatment plans. However, there are also concerns about privacy, ethics, and the potential for bias in AI algorithms. It will be important for healthcare providers to carefully consider these issues and ensure that AI is used in a responsible and ethical manner.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **19. Knowledge Expansion**"
      ],
      "metadata": {
        "id": "LDI1euWRcqga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Expand on this idea: 'Renewable energy is critical for combating climate change.' Include examples and relevant technologies.\"\n",
        "response = openai.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=100,\n",
        "    temperature=0\n",
        ")\n",
        "print(\"Success Case:\", response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOQcBcw_cum0",
        "outputId": "2cb4ff40-8d60-428f-d68d-364557438700"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success Case: Renewable energy is essential in the fight against climate change because it offers a sustainable alternative to fossil fuels, which are the primary drivers of global warming. By harnessing energy sources that are naturally replenished, such as sunlight, wind, and water, we can significantly reduce greenhouse gas emissions and mitigate the impacts of climate change.\n",
            "\n",
            "One of the most widely used forms of renewable energy is solar power. Solar panels convert sunlight into electricity, providing a clean and abundant source of energy. In recent years,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Why is renewable energy important?\"  # No explicit request to expand on the idea\n",
        "response = openai.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=100,\n",
        "    temperature=0\n",
        ")\n",
        "print(\"Failure Case:\", response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAZmKro9cvv-",
        "outputId": "59bac45e-331f-458e-fc20-08fd8de116e1"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failure Case: Renewable energy is important for several reasons:\n",
            "\n",
            "1. Environmental benefits: Renewable energy sources such as solar, wind, and hydropower produce significantly lower levels of greenhouse gas emissions compared to fossil fuels. This helps to reduce air pollution, combat climate change, and protect the environment.\n",
            "\n",
            "2. Energy security: Renewable energy sources are abundant and widely available, reducing our dependence on finite and imported fossil fuels. This helps to enhance energy security and reduce the risk of supply disruptions.\n",
            "\n",
            "3. Economic benefits:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **20. Hypothetical Scenarios**"
      ],
      "metadata": {
        "id": "vlryhlq9cyHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Imagine a world where humans can communicate directly with animals. Describe how society would change.\"\n",
        "response = openai.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=100,\n",
        "    temperature=0\n",
        ")\n",
        "print(\"Success Case:\", response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndtv6Fzwcy6Q",
        "outputId": "36310c01-1741-4f87-80de-dac9bd3c0959"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success Case: In a world where humans can communicate directly with animals, society would undergo significant changes. \n",
            "\n",
            "First and foremost, there would likely be a newfound respect and understanding for animals. People would be able to communicate with them on a deeper level, learning about their needs, desires, and emotions. This would lead to more compassionate treatment of animals, as humans would be able to better understand their perspectives and advocate for their well-being.\n",
            "\n",
            "This newfound ability to communicate with animals could also have a profound impact on industries such\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"What would happen if humans could talk to animals?\"  # No explicit request to describe broader societal impact\n",
        "response = openai.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=100,\n",
        "    temperature=0\n",
        ")\n",
        "print(\"Failure Case:\", response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecqxHJNgc0Kx",
        "outputId": "d8364d12-8c23-4ac7-e075-fb44958362cc"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failure Case: If humans could talk to animals, it would likely lead to a better understanding and communication between the two species. This could potentially lead to improved relationships, better care for animals, and a deeper appreciation for the natural world. Humans could learn more about animal behavior, needs, and emotions, leading to more ethical treatment of animals and potentially reducing instances of animal cruelty. Additionally, it could open up new possibilities for collaboration and cooperation between humans and animals in various fields such as conservation, research, and therapy.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **21. Parallel Problem Solving**"
      ],
      "metadata": {
        "id": "2sUvFHeKc1ZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Explore two different solutions to reduce traffic congestion in urban areas. Provide pros and cons for each solution.\"\n",
        "response = openai.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=150,\n",
        "    temperature=0\n",
        ")\n",
        "print(\"Success Case:\", response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tEKTbXoc3MV",
        "outputId": "1e26f2d4-2e31-47f8-842f-b2d758fa1941"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success Case: 1. Implementing congestion pricing:\n",
            "\n",
            "Pros:\n",
            "- Encourages people to use public transportation or carpooling, reducing the number of vehicles on the road\n",
            "- Generates revenue that can be used to improve public transportation infrastructure\n",
            "- Can help reduce air pollution and greenhouse gas emissions\n",
            "\n",
            "Cons:\n",
            "- Can be seen as unfair to low-income individuals who may not be able to afford the tolls\n",
            "- Implementation costs can be high\n",
            "- May lead to increased traffic on alternate routes as drivers try to avoid paying the toll\n",
            "\n",
            "2. Investing in infrastructure for alternative modes of transportation:\n",
            "\n",
            "Pros:\n",
            "- Encourages people to use public transportation, biking, or walking instead of driving\n",
            "- Can help reduce traffic congestion and improve air quality\n",
            "- Provides more transportation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"How can we reduce traffic congestion in cities?\"  # No explicit request for multiple solutions or comparisons\n",
        "response = openai.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens=150,\n",
        "    temperature=0\n",
        ")\n",
        "print(\"Failure Case:\", response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hRtad7vc4N2",
        "outputId": "14b29789-9785-4483-ab1c-cc328607ddef"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failure Case: 1. Improve public transportation: Investing in efficient and reliable public transportation systems can encourage more people to use public transportation instead of driving their cars, reducing the number of vehicles on the road.\n",
            "\n",
            "2. Implement congestion pricing: Charging drivers a fee to enter certain congested areas during peak hours can help reduce traffic congestion by encouraging people to carpool, use public transportation, or drive during off-peak hours.\n",
            "\n",
            "3. Promote alternative modes of transportation: Encouraging walking, cycling, and ridesharing can help reduce the number of cars on the road and alleviate traffic congestion.\n",
            "\n",
            "4. Implement smart traffic management systems: Using technology to monitor traffic flow, adjust traffic signals, and provide real-time traffic information to drivers can help optimize traffic flow and reduce congestion\n"
          ]
        }
      ]
    }
  ]
}